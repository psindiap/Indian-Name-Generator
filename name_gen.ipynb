{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-901547fb-0e25-4a3b-8f59-543af112ecad",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "231eca8f",
    "execution_start": 1628245662106,
    "execution_millis": 18,
    "deepnote_cell_type": "code"
   },
   "source": "import pandas as pd \nimport numpy as np\nfrom keras.layers import SimpleRNN, Dense, Activation, TimeDistributed\nfrom keras.models import Sequential\nns = pd.read_csv(\"/work/Indian_Names.csv\") \nns=ns.iloc[:,1]\ndf = pd.DataFrame({'Name':ns})\n\n\ndf['Name']=df['Name'].astype(str)\n\n\n\n",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": "2021-08-06 10:27:39.936942: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-08-06 10:27:39.936993: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "\nprint(df)",
   "metadata": {
    "tags": [],
    "cell_id": "00001-7282e0a3-47f3-40a9-bcda-4dfa0972ffaa",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "15f84648",
    "execution_start": 1628245664399,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "           Name\n0         aabid\n1        aabida\n2        aachal\n3        aadesh\n4         aadil\n...         ...\n6496     pratha\n6497    preetha\n6498    pratham\n6499  samriddhi\n6500     akshit\n\n[6501 rows x 1 columns]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "df['Name'] = df['Name'].apply(lambda x : '\\t' + x)\ndf['target'] = df['Name'].apply(lambda x : x[1:len(x)] + '\\n')\nprint(df)",
   "metadata": {
    "tags": [],
    "cell_id": "00001-e2dd7691-4d65-4de4-8291-7d8d0a72addf",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "71ee1231",
    "execution_start": 1628245670741,
    "execution_millis": 11,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "             Name       target\n0         \\taabid      aabid\\n\n1        \\taabida     aabida\\n\n2        \\taachal     aachal\\n\n3        \\taadesh     aadesh\\n\n4         \\taadil      aadil\\n\n...           ...          ...\n6496     \\tpratha     pratha\\n\n6497    \\tpreetha    preetha\\n\n6498    \\tpratham    pratham\\n\n6499  \\tsamriddhi  samriddhi\\n\n6500     \\takshit     akshit\\n\n\n[6501 rows x 2 columns]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "def get_vocabulary(names):\n    vocabulary = set(['\\t', '\\n'])\n    for name in names:\n        for c in name:\n            if c not in vocabulary:\n                vocabulary.add(c)\n                \n    return vocabulary\n\ndef get_max_len(names):    \n    length_list=[]\n    for l in names:        \n        length_list.append(len(l))    \n    max_len = np.max(length_list)\n    return max_len\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00002-57dddb5e-e725-4f28-8d8a-8923162d0d26",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c2f56acd",
    "execution_start": 1628245677297,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "vocabulary = get_vocabulary(df['Name'])\nctoi = { char : idx for idx, char in enumerate(sorted(vocabulary))}\nitoc = { idx : char for idx, char in enumerate(sorted(vocabulary))}\n\nmax_len = get_max_len(df.Name)\n\ninput_data = np.zeros((len(df.Name), max_len+1, len(vocabulary)),dtype='float32')\ntarget_data = np.zeros((len(df.Name), max_len+1, len(vocabulary)),dtype='float32')",
   "metadata": {
    "tags": [],
    "cell_id": "00003-dff659d0-3f67-4797-b3e9-003b5c9a9499",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c2324167",
    "execution_start": 1628245679316,
    "execution_millis": 16,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "for n_idx, name in enumerate(df['Name']):\n  for c_idx, char in enumerate(name):\n    input_data[n_idx, c_idx, ctoi[char]] = 1.\n\n# Iterate for each name in the dataset\nfor n_idx, name in enumerate(df['target']):\n  for c_idx, char in enumerate(name):\n    target_data[n_idx, c_idx, ctoi[char]] = 1.",
   "metadata": {
    "tags": [],
    "cell_id": "00004-54bc5ca8-5b17-4a10-9744-aea7d9793a25",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b21083bd",
    "execution_start": 1628245681290,
    "execution_millis": 59,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "model = Sequential()\nmodel.add(SimpleRNN(50, input_shape=(max_len+1, len(vocabulary)),return_sequences=True))\nmodel.add(TimeDistributed(Dense(len(vocabulary), activation='softmax')))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\nmodel.summary()",
   "metadata": {
    "tags": [],
    "cell_id": "00005-3d768ca7-135e-4260-adf5-0190197d0c69",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bc1aef96",
    "execution_start": 1628245683407,
    "execution_millis": 209,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nsimple_rnn (SimpleRNN)       (None, 21, 50)            4350      \n_________________________________________________________________\ntime_distributed (TimeDistri (None, 21, 36)            1836      \n=================================================================\nTotal params: 6,186\nTrainable params: 6,186\nNon-trainable params: 0\n_________________________________________________________________\n2021-08-06 10:28:03.421150: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-08-06 10:28:03.421440: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2021-08-06 10:28:03.421466: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n2021-08-06 10:28:03.421499: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-bbd6a6d2-aec1-4ac4-a4d3-96894f078b54): /proc/driver/nvidia/version does not exist\n2021-08-06 10:28:03.421770: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-08-06 10:28:03.421936: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": "model.fit(input_data, target_data, batch_size=128, epochs=32)",
   "metadata": {
    "tags": [],
    "cell_id": "00006-57ed45bf-5c12-4051-a513-b5ca62f394e0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "75decff",
    "execution_start": 1628245995369,
    "execution_millis": 20186,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/32\n51/51 [==============================] - 1s 13ms/step - loss: 0.6831\nEpoch 2/32\n51/51 [==============================] - 1s 13ms/step - loss: 0.6806\nEpoch 3/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6803\nEpoch 4/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6802\nEpoch 5/32\n51/51 [==============================] - 1s 13ms/step - loss: 0.6799\nEpoch 6/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6797\nEpoch 7/32\n51/51 [==============================] - 1s 11ms/step - loss: 0.6797\nEpoch 8/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6795\nEpoch 9/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6792\nEpoch 10/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6795\nEpoch 11/32\n51/51 [==============================] - 1s 13ms/step - loss: 0.6792\nEpoch 12/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6791\nEpoch 13/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6790\nEpoch 14/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6788\nEpoch 15/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6787\nEpoch 16/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6789\nEpoch 17/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6786\nEpoch 18/32\n51/51 [==============================] - 1s 14ms/step - loss: 0.6785\nEpoch 19/32\n51/51 [==============================] - 1s 11ms/step - loss: 0.6783\nEpoch 20/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6781\nEpoch 21/32\n51/51 [==============================] - 1s 13ms/step - loss: 0.6780\nEpoch 22/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6781\nEpoch 23/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6778\nEpoch 24/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6775\nEpoch 25/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6775\nEpoch 26/32\n51/51 [==============================] - 1s 13ms/step - loss: 0.6773\nEpoch 27/32\n51/51 [==============================] - 1s 14ms/step - loss: 0.6772\nEpoch 28/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6772\nEpoch 29/32\n51/51 [==============================] - 1s 13ms/step - loss: 0.6770\nEpoch 30/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6768\nEpoch 31/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6768\nEpoch 32/32\n51/51 [==============================] - 1s 12ms/step - loss: 0.6768\n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 16,
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f1024400cd0>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": "output_seq = np.zeros((1, max_len+1, len(vocabulary)))\noutput_seq[0, 0, ctoi['\\t']] = 1\n\n# Get the probabilities for the first character\nprobs = model.predict_proba(output_seq, verbose=0)[:,1,:]\n\n\n# Sample vocabulary to get first character\nfirst_char = np.random.choice(sorted(list(vocabulary)), replace=False,p=probs.reshape(len(vocabulary)))\n\n# Print the character generated\nprint(first_char)\n\n# Update the vector to contain first the character\noutput_seq[0, 1, ctoi[first_char]] = 1.\n\n# Get the probabilities for the second character\nprobs = model.predict_proba(output_seq, verbose=0)[:,2,:]\n\n# Sample vocabulary to get second character\nsecond_char = np.random.choice(sorted(list(vocabulary)), replace=False,p=probs.reshape(len(vocabulary)))\n\n\n# Print the second character\nprint(second_char)",
   "metadata": {
    "tags": [],
    "cell_id": "00007-7b82aaf5-97f7-4470-9a2c-965a90faabef",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bd422f4e",
    "execution_start": 1628246015591,
    "execution_millis": 210,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "o\nn\n/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n  warnings.warn('`model.predict_proba()` is deprecated and '\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": "def generate_names(n):\n    for i in range(0,n):        \n        stop=False        \n        counter=1        \n        name = ''     \n        output_seq = np.zeros((1, max_len+1, len(vocabulary)))        \n        output_seq[0, 0, ctoi['\\t']] = 1.\n        while stop == False and counter < 10:            \n            probs = model.predict_proba(output_seq, verbose=0)[:,counter-1,:]       \n            c = np.random.choice(sorted(list(vocabulary)), replace=False, p=probs.reshape(len(vocabulary)))\n            if c=='\\n':                \n                stop=True \n            else:                \n                name = name + c                \n                output_seq[0,counter , ctoi[c]] = 1.                \n                counter=counter+1        \n        print(name)\n",
   "metadata": {
    "tags": [],
    "cell_id": "00007-b2e1393c-e923-4779-84d0-f3e1544f96c0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "54ac16d7",
    "execution_start": 1628246019446,
    "execution_millis": 2,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": "generate_names(10)",
   "metadata": {
    "tags": [],
    "cell_id": "00008-21d61777-7d0d-4ef6-b136-3a7fbf2a0ebe",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1cf6eaa4",
    "execution_start": 1628246123563,
    "execution_millis": 2244,
    "is_code_hidden": false,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "ramin\nraivakhvi\nmohav\nnikin\nbhadi\nsarhoo\nwejina\nsavender\ncharjup\nchhadai\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=bbd6a6d2-aec1-4ac4-a4d3-96894f078b54' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "27a3b008-7ea0-4403-8a27-18943c0c6ce2",
  "deepnote_execution_queue": []
 }
}